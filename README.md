# Compare
对DRQN网络和DQN网络的结果进行了比较。

经过比较以后发现，DRQN网络的损失函数确实会DQN更加陡峭，但是奖励函数对比DQN有微小的差距。

在设计DRQN网络的时候，我们一开始将STEP_SIZE设置为5，但是发现在这种情况下，无法将REWARD同环境状态对应好，因此只能将STEP_SIZE设置为1尝试，最终成功。因此，这部分对于DRQN的理解应该说还是存在偏差的。
